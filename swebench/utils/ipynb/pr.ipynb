{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算仓库pr数量\n",
    "def parse_pull_requests(file_path):\n",
    "    repo_pr_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        previous_line = None\n",
    "\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"pull requests\" in line:\n",
    "                # Store the previous line containing repo and PR count\n",
    "                previous_line = line\n",
    "            elif line.startswith(\"Done:\") and previous_line:\n",
    "                # Extract repo and PR count from the previous line\n",
    "                repo_name, pr_info = previous_line.split(\":\")\n",
    "                pr_count = int(pr_info.split()[0])  # Get the number of pull requests\n",
    "                repo_pr_map[repo_name] = pr_count\n",
    "                previous_line = None  # Reset the previous line\n",
    "\n",
    "    # Sort the repositories by pull request count in descending order\n",
    "    sorted_repos = sorted(repo_pr_map.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the sorted repositories\n",
    "    for repo, pr_count in sorted_repos:\n",
    "        print(f\"{repo}: {pr_count} pull requests\")\n",
    "\n",
    "# Example usage\n",
    "file_path = '/home/riv3r/SWE-bench/swebench/collect/logs/pr_log'\n",
    "parse_pull_requests(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "\n",
    "def get_pull_request(repo_owner, repo_name, pr_number, access_token=None):\n",
    "    url = f\"{GITHUB_API_URL}/repos/{repo_owner}/{repo_name}/pulls/{pr_number}\"\n",
    "    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "    if access_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"PR fetched: {response.json()}\")\n",
    "        return response.json()  # 返回 PR 的详细信息\n",
    "    else:\n",
    "        print(f\"Failed to fetch PR: {response.status_code} - {response.json()}\")\n",
    "        return None\n",
    "    \n",
    "a = get_pull_request(\"tokio-rs\",\"tokio\", \"3965\",os.getenv('GITHUB_TOKEN')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_code(repo, commit, file_path, location, access_token=None):\n",
    "    \"\"\"\n",
    "    获取指定仓库某个提交中某文件的函数代码。\n",
    "\n",
    "    :param repo: str, 仓库名称 (格式: owner/repo_name)\n",
    "    :param commit: str, 提交哈希值或分支名称\n",
    "    :param file_path: str, 文件的路径\n",
    "    :param location: tuple, 函数所在的起始行和结束行 (start_line, end_line)\n",
    "    :param access_token: str, GitHub 的个人访问令牌（可选）\n",
    "    :return: str, 函数的代码\n",
    "    \"\"\"\n",
    "    # 构建 GitHub API 请求 URL\n",
    "    url = f\"{GITHUB_API_URL}/repos/{repo}/contents/{file_path}?ref={commit}\"\n",
    "    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "    if access_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "\n",
    "    # 获取文件内容\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch file: {response.status_code} - {response.json()}\")\n",
    "        return None\n",
    "\n",
    "    # 解码文件内容 (Base64 编码)\n",
    "    file_data = response.json()\n",
    "    file_content = base64.b64decode(file_data[\"content\"]).decode(\"utf-8\")\n",
    "\n",
    "    # 提取函数代码\n",
    "    start_line, end_line = location\n",
    "    file_lines = file_content.splitlines()\n",
    "    function_code = \"\\n\".join(file_lines[start_line - 1:end_line])  # 注意行号从 1 开始\n",
    "\n",
    "    return function_code\n",
    "\n",
    "# Example usage\n",
    "import base64\n",
    "repo = \"tokio-rs/tokio\"\n",
    "commit = \"aef2d64b0a519ff6726f8c139ee1d3e6b1959b0b\"\n",
    "file_path = \"tokio/Cargo.toml\"\n",
    "location = (1, 70)\n",
    "access_token = os.getenv('GITHUB_TOKEN')\n",
    "code = get_function_code(repo, commit, file_path, location, access_token)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokio-rs__tokio-3965\n",
      "['tokio/src/runtime/task/harness.rs']\n",
      "{'tokio/src/runtime/task/harness.rs': [(420, 427)]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"r1v3r/RustGPT_Bench_verified\",split=\"train\")\n",
    "\n",
    "def extract_file_paths_and_locations(patch_text):\n",
    "    \"\"\"\n",
    "    解析 unidiff 格式的 patch, 提取旧文件的文件路径和被修改的行号。\n",
    "\n",
    "    返回旧文件路径列表和对应文件的修改行号字典。\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    locations = {}\n",
    "    current_file = None\n",
    "    \n",
    "    for line in patch_text.splitlines():\n",
    "        if line.startswith('--- '):\n",
    "            # 原文件路径\n",
    "            original_file = line[6:].strip()\n",
    "            current_file = original_file\n",
    "            if current_file.endswith('.rs'):\n",
    "                file_paths.append(current_file)\n",
    "            locations[current_file] = []\n",
    "        elif line.startswith('@@ '):\n",
    "            # hunks，提取旧文件的行号范围\n",
    "            match = re.match(r'@@ -(\\d+)(?:,(\\d+))? \\+\\d+(?:,\\d+)? @@', line)\n",
    "            if match:\n",
    "                start_line = int(match.group(1))\n",
    "                line_count = int(match.group(2)) if match.group(2) else 1\n",
    "                location = (start_line, start_line + line_count)\n",
    "                locations[current_file].append(location)\n",
    "    return file_paths, locations\n",
    "\n",
    "\n",
    "\n",
    "print(dataset[0][\"instance_id\"])\n",
    "file_paths, locations = extract_file_paths_and_locations(dataset[0][\"patch\"])\n",
    "print(file_paths)\n",
    "print(locations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:3: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:3: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "/tmp/ipykernel_4213/4209468273.py:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  'tokio/src/runtime/task/harness.rs': [(420, 427)(420, 427)(420, 427)(420, 427)(420, 427)(420, 427)],\n",
      "/tmp/ipykernel_4213/4209468273.py:3: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  'tokio/src/runtime/task/harness.rs': [(420, 427)(420, 427)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m locations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokio/src/runtime/task/harness.rs\u001b[39m\u001b[38;5;124m'\u001b[39m: [(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokio/src/runtime/task/harness.rs\u001b[39m\u001b[38;5;124m'\u001b[39m: [(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)(\u001b[38;5;241m420\u001b[39m, \u001b[38;5;241m427\u001b[39m)]\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(locations\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "locations = {\n",
    "    'tokio/src/runtime/task/harness.rs': [(420, 427)(420, 427)(420, 427)(420, 427)(420, 427)(420, 427)],\n",
    "    'tokio/src/runtime/task/harness.rs': [(420, 427)(420, 427)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use crate::future::Future;\n",
      "use crate::runtime::task::core::{Cell, Core, CoreStage, Header, Scheduler, Trailer};\n",
      "use crate::runtime::task::state::Snapshot;\n",
      "use crate::runtime::task::waker::waker_ref;\n",
      "use crate::runtime::task::{JoinError, Notified, Schedule, Task};\n",
      "\n",
      "use std::mem;\n",
      "use std::panic;\n",
      "use std::ptr::NonNull;\n",
      "use std::task::{Context, Poll, Waker};\n",
      "\n",
      "/// Typed raw task handle\n",
      "pub(super) struct Harness<T: Future, S: 'static> {\n",
      "    cell: NonNull<Cell<T, S>>,\n",
      "}\n",
      "\n",
      "impl<T, S> Harness<T, S>\n",
      "where\n",
      "    T: Future,\n",
      "    S: 'static,\n",
      "{\n",
      "    pub(super) unsafe fn from_raw(ptr: NonNull<Header>) -> Harness<T, S> {\n",
      "        Harness {\n",
      "            cell: ptr.cast::<Cell<T, S>>(),\n",
      "        }\n",
      "    }\n",
      "\n",
      "    fn header(&self) -> &Header {\n",
      "        unsafe { &self.cell.as_ref().header }\n",
      "    }\n",
      "\n",
      "    fn trailer(&self) -> &Trailer {\n",
      "        unsafe { &self.cell.as_ref().trailer }\n",
      "    }\n",
      "\n",
      "    fn core(&self) -> &Core<T, S> {\n",
      "        unsafe { &self.cell.as_ref().core }\n",
      "    }\n",
      "\n",
      "    fn scheduler_view(&self) -> SchedulerView<'_, S> {\n",
      "        SchedulerView {\n",
      "            header: self.header(),\n",
      "            scheduler: &self.core().scheduler,\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "impl<T, S> Harness<T, S>\n",
      "where\n",
      "    T: Future,\n",
      "    S: Schedule,\n",
      "{\n",
      "    /// Polls the inner future.\n",
      "    ///\n",
      "    /// All necessary state checks and transitions are performed.\n",
      "    ///\n",
      "    /// Panics raised while polling the future are handled.\n",
      "    pub(super) fn poll(self) {\n",
      "        match self.poll_inner() {\n",
      "            PollFuture::Notified => {\n",
      "                // Signal yield\n",
      "                self.core().scheduler.yield_now(Notified(self.to_task()));\n",
      "                // The ref-count was incremented as part of\n",
      "                // `transition_to_idle`.\n",
      "                self.drop_reference();\n",
      "            }\n",
      "            PollFuture::DropReference => {\n",
      "                self.drop_reference();\n",
      "            }\n",
      "            PollFuture::Complete(out, is_join_interested) => {\n",
      "                self.complete(out, is_join_interested);\n",
      "            }\n",
      "            PollFuture::None => (),\n",
      "        }\n",
      "    }\n",
      "\n",
      "    fn poll_inner(&self) -> PollFuture<T::Output> {\n",
      "        let snapshot = match self.scheduler_view().transition_to_running() {\n",
      "            TransitionToRunning::Ok(snapshot) => snapshot,\n",
      "            TransitionToRunning::DropReference => return PollFuture::DropReference,\n",
      "        };\n",
      "\n",
      "        // The transition to `Running` done above ensures that a lock on the\n",
      "        // future has been obtained. This also ensures the `*mut T` pointer\n",
      "        // contains the future (as opposed to the output) and is initialized.\n",
      "\n",
      "        let waker_ref = waker_ref::<T, S>(self.header());\n",
      "        let cx = Context::from_waker(&*waker_ref);\n",
      "        poll_future(self.header(), &self.core().stage, snapshot, cx)\n",
      "    }\n",
      "\n",
      "    pub(super) fn dealloc(self) {\n",
      "        // Release the join waker, if there is one.\n",
      "        self.trailer().waker.with_mut(drop);\n",
      "\n",
      "        // Check causality\n",
      "        self.core().stage.with_mut(drop);\n",
      "        self.core().scheduler.with_mut(drop);\n",
      "\n",
      "        unsafe {\n",
      "            drop(Box::from_raw(self.cell.as_ptr()));\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // ===== join handle =====\n",
      "\n",
      "    /// Read the task output into `dst`.\n",
      "    pub(super) fn try_read_output(self, dst: &mut Poll<super::Result<T::Output>>, waker: &Waker) {\n",
      "        if can_read_output(self.header(), self.trailer(), waker) {\n",
      "            *dst = Poll::Ready(self.core().stage.take_output());\n",
      "        }\n",
      "    }\n",
      "\n",
      "    pub(super) fn drop_join_handle_slow(self) {\n",
      "        // Try to unset `JOIN_INTEREST`. This must be done as a first step in\n",
      "        // case the task concurrently completed.\n",
      "        if self.header().state.unset_join_interested().is_err() {\n",
      "            // It is our responsibility to drop the output. This is critical as\n",
      "            // the task output may not be `Send` and as such must remain with\n",
      "            // the scheduler or `JoinHandle`. i.e. if the output remains in the\n",
      "            // task structure until the task is deallocated, it may be dropped\n",
      "            // by a Waker on any arbitrary thread.\n",
      "            self.core().stage.drop_future_or_output();\n",
      "        }\n",
      "\n",
      "        // Drop the `JoinHandle` reference, possibly deallocating the task\n",
      "        self.drop_reference();\n",
      "    }\n",
      "\n",
      "    // ===== waker behavior =====\n",
      "\n",
      "    pub(super) fn wake_by_val(self) {\n",
      "        self.wake_by_ref();\n",
      "        self.drop_reference();\n",
      "    }\n",
      "\n",
      "    pub(super) fn wake_by_ref(&self) {\n",
      "        if self.header().state.transition_to_notified() {\n",
      "            self.core().scheduler.schedule(Notified(self.to_task()));\n",
      "        }\n",
      "    }\n",
      "\n",
      "    pub(super) fn drop_reference(self) {\n",
      "        if self.header().state.ref_dec() {\n",
      "            self.dealloc();\n",
      "        }\n",
      "    }\n",
      "\n",
      "    #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n",
      "    pub(super) fn id(&self) -> Option<&tracing::Id> {\n",
      "        self.header().id.as_ref()\n",
      "    }\n",
      "\n",
      "    /// Forcibly shutdown the task\n",
      "    ///\n",
      "    /// Attempt to transition to `Running` in order to forcibly shutdown the\n",
      "    /// task. If the task is currently running or in a state of completion, then\n",
      "    /// there is nothing further to do. When the task completes running, it will\n",
      "    /// notice the `CANCELLED` bit and finalize the task.\n",
      "    pub(super) fn shutdown(self) {\n",
      "        if !self.header().state.transition_to_shutdown() {\n",
      "            // The task is concurrently running. No further work needed.\n",
      "            return;\n",
      "        }\n",
      "\n",
      "        // By transitioning the lifecycle to `Running`, we have permission to\n",
      "        // drop the future.\n",
      "        let err = cancel_task(&self.core().stage);\n",
      "        self.complete(Err(err), true)\n",
      "    }\n",
      "\n",
      "    /// Remotely abort the task\n",
      "    ///\n",
      "    /// This is similar to `shutdown` except that it asks the runtime to perform\n",
      "    /// the shutdown. This is necessary to avoid the shutdown happening in the\n",
      "    /// wrong thread for non-Send tasks.\n",
      "    pub(super) fn remote_abort(self) {\n",
      "        if self.header().state.transition_to_notified_and_cancel() {\n",
      "            self.core().scheduler.schedule(Notified(self.to_task()));\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // ====== internal ======\n",
      "\n",
      "    fn complete(self, output: super::Result<T::Output>, is_join_interested: bool) {\n",
      "        if is_join_interested {\n",
      "            // Store the output. The future has already been dropped\n",
      "            //\n",
      "            // Safety: Mutual exclusion is obtained by having transitioned the task\n",
      "            // state -> Running\n",
      "            let stage = &self.core().stage;\n",
      "            stage.store_output(output);\n",
      "\n",
      "            // Transition to `Complete`, notifying the `JoinHandle` if necessary.\n",
      "            transition_to_complete(self.header(), stage, &self.trailer());\n",
      "        }\n",
      "\n",
      "        // The task has completed execution and will no longer be scheduled.\n",
      "        //\n",
      "        // Attempts to batch a ref-dec with the state transition below.\n",
      "\n",
      "        if self\n",
      "            .scheduler_view()\n",
      "            .transition_to_terminal(is_join_interested)\n",
      "        {\n",
      "            self.dealloc()\n",
      "        }\n",
      "    }\n",
      "\n",
      "    fn to_task(&self) -> Task<S> {\n",
      "        self.scheduler_view().to_task()\n",
      "    }\n",
      "}\n",
      "\n",
      "enum TransitionToRunning {\n",
      "    Ok(Snapshot),\n",
      "    DropReference,\n",
      "}\n",
      "\n",
      "struct SchedulerView<'a, S> {\n",
      "    header: &'a Header,\n",
      "    scheduler: &'a Scheduler<S>,\n",
      "}\n",
      "\n",
      "impl<'a, S> SchedulerView<'a, S>\n",
      "where\n",
      "    S: Schedule,\n",
      "{\n",
      "    fn to_task(&self) -> Task<S> {\n",
      "        // SAFETY The header is from the same struct containing the scheduler `S` so  the cast is safe\n",
      "        unsafe { Task::from_raw(self.header.into()) }\n",
      "    }\n",
      "\n",
      "    /// Returns true if the task should be deallocated.\n",
      "    fn transition_to_terminal(&self, is_join_interested: bool) -> bool {\n",
      "        let ref_dec = if self.scheduler.is_bound() {\n",
      "            if let Some(task) = self.scheduler.release(self.to_task()) {\n",
      "                mem::forget(task);\n",
      "                true\n",
      "            } else {\n",
      "                false\n",
      "            }\n",
      "        } else {\n",
      "            false\n",
      "        };\n",
      "\n",
      "        // This might deallocate\n",
      "        let snapshot = self\n",
      "            .header\n",
      "            .state\n",
      "            .transition_to_terminal(!is_join_interested, ref_dec);\n",
      "\n",
      "        snapshot.ref_count() == 0\n",
      "    }\n",
      "\n",
      "    fn transition_to_running(&self) -> TransitionToRunning {\n",
      "        // If this is the first time the task is polled, the task will be bound\n",
      "        // to the scheduler, in which case the task ref count must be\n",
      "        // incremented.\n",
      "        let is_not_bound = !self.scheduler.is_bound();\n",
      "\n",
      "        // Transition the task to the running state.\n",
      "        //\n",
      "        // A failure to transition here indicates the task has been cancelled\n",
      "        // while in the run queue pending execution.\n",
      "        let snapshot = match self.header.state.transition_to_running(is_not_bound) {\n",
      "            Ok(snapshot) => snapshot,\n",
      "            Err(_) => {\n",
      "                // The task was shutdown while in the run queue. At this point,\n",
      "                // we just hold a ref counted reference. Since we do not have access to it here\n",
      "                // return `DropReference` so the caller drops it.\n",
      "                return TransitionToRunning::DropReference;\n",
      "            }\n",
      "        };\n",
      "\n",
      "        if is_not_bound {\n",
      "            // Ensure the task is bound to a scheduler instance. Since this is\n",
      "            // the first time polling the task, a scheduler instance is pulled\n",
      "            // from the local context and assigned to the task.\n",
      "            //\n",
      "            // The scheduler maintains ownership of the task and responds to\n",
      "            // `wake` calls.\n",
      "            //\n",
      "            // The task reference count has been incremented.\n",
      "            //\n",
      "            // Safety: Since we have unique access to the task so that we can\n",
      "            // safely call `bind_scheduler`.\n",
      "            self.scheduler.bind_scheduler(self.to_task());\n",
      "        }\n",
      "        TransitionToRunning::Ok(snapshot)\n",
      "    }\n",
      "}\n",
      "\n",
      "/// Transitions the task's lifecycle to `Complete`. Notifies the\n",
      "/// `JoinHandle` if it still has interest in the completion.\n",
      "fn transition_to_complete<T>(header: &Header, stage: &CoreStage<T>, trailer: &Trailer)\n",
      "where\n",
      "    T: Future,\n",
      "{\n",
      "    // Transition the task's lifecycle to `Complete` and get a snapshot of\n",
      "    // the task's sate.\n",
      "    let snapshot = header.state.transition_to_complete();\n",
      "\n",
      "    if !snapshot.is_join_interested() {\n",
      "        // The `JoinHandle` is not interested in the output of this task. It\n",
      "        // is our responsibility to drop the output.\n",
      "        stage.drop_future_or_output();\n",
      "    } else if snapshot.has_join_waker() {\n",
      "        // Notify the join handle. The previous transition obtains the\n",
      "        // lock on the waker cell.\n",
      "        trailer.wake_join();\n",
      "    }\n",
      "}\n",
      "\n",
      "fn can_read_output(header: &Header, trailer: &Trailer, waker: &Waker) -> bool {\n",
      "    // Load a snapshot of the current task state\n",
      "    let snapshot = header.state.load();\n",
      "\n",
      "    debug_assert!(snapshot.is_join_interested());\n",
      "\n",
      "    if !snapshot.is_complete() {\n",
      "        // The waker must be stored in the task struct.\n",
      "        let res = if snapshot.has_join_waker() {\n",
      "            // There already is a waker stored in the struct. If it matches\n",
      "            // the provided waker, then there is no further work to do.\n",
      "            // Otherwise, the waker must be swapped.\n",
      "            let will_wake = unsafe {\n",
      "                // Safety: when `JOIN_INTEREST` is set, only `JOIN_HANDLE`\n",
      "                // may mutate the `waker` field.\n",
      "                trailer.will_wake(waker)\n",
      "            };\n",
      "\n",
      "            if will_wake {\n",
      "                // The task is not complete **and** the waker is up to date,\n",
      "                // there is nothing further that needs to be done.\n",
      "                return false;\n",
      "            }\n",
      "\n",
      "            // Unset the `JOIN_WAKER` to gain mutable access to the `waker`\n",
      "            // field then update the field with the new join worker.\n",
      "            //\n",
      "            // This requires two atomic operations, unsetting the bit and\n",
      "            // then resetting it. If the task transitions to complete\n",
      "            // concurrently to either one of those operations, then setting\n",
      "            // the join waker fails and we proceed to reading the task\n",
      "            // output.\n",
      "            header\n",
      "                .state\n",
      "                .unset_waker()\n",
      "                .and_then(|snapshot| set_join_waker(header, trailer, waker.clone(), snapshot))\n",
      "        } else {\n",
      "            set_join_waker(header, trailer, waker.clone(), snapshot)\n",
      "        };\n",
      "\n",
      "        match res {\n",
      "            Ok(_) => return false,\n",
      "            Err(snapshot) => {\n",
      "                assert!(snapshot.is_complete());\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    true\n",
      "}\n",
      "\n",
      "fn set_join_waker(\n",
      "    header: &Header,\n",
      "    trailer: &Trailer,\n",
      "    waker: Waker,\n",
      "    snapshot: Snapshot,\n",
      ") -> Result<Snapshot, Snapshot> {\n",
      "    assert!(snapshot.is_join_interested());\n",
      "    assert!(!snapshot.has_join_waker());\n",
      "\n",
      "    // Safety: Only the `JoinHandle` may set the `waker` field. When\n",
      "    // `JOIN_INTEREST` is **not** set, nothing else will touch the field.\n",
      "    unsafe {\n",
      "        trailer.set_waker(Some(waker));\n",
      "    }\n",
      "\n",
      "    // Update the `JoinWaker` state accordingly\n",
      "    let res = header.state.set_join_waker();\n",
      "\n",
      "    // If the state could not be updated, then clear the join waker\n",
      "    if res.is_err() {\n",
      "        unsafe {\n",
      "            trailer.set_waker(None);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    res\n",
      "}\n",
      "\n",
      "enum PollFuture<T> {\n",
      "    Complete(Result<T, JoinError>, bool),\n",
      "    DropReference,\n",
      "    Notified,\n",
      "    None,\n",
      "}\n",
      "\n",
      "fn cancel_task<T: Future>(stage: &CoreStage<T>) -> JoinError {\n",
      "    // Drop the future from a panic guard.\n",
      "    let res = panic::catch_unwind(panic::AssertUnwindSafe(|| {\n",
      "        stage.drop_future_or_output();\n",
      "    }));\n",
      "\n",
      "    if let Err(err) = res {\n",
      "        // Dropping the future panicked, complete the join\n",
      "        // handle with the panic to avoid dropping the panic\n",
      "        // on the ground.\n",
      "        JoinError::panic(err)\n",
      "    } else {\n",
      "        JoinError::cancelled()\n",
      "    }\n",
      "}\n",
      "\n",
      "fn poll_future<T: Future>(\n",
      "    header: &Header,\n",
      "    core: &CoreStage<T>,\n",
      "    snapshot: Snapshot,\n",
      "    cx: Context<'_>,\n",
      ") -> PollFuture<T::Output> {\n",
      "    if snapshot.is_cancelled() {\n",
      "        PollFuture::Complete(Err(JoinError::cancelled()), snapshot.is_join_interested())\n",
      "    } else {\n",
      "        let res = panic::catch_unwind(panic::AssertUnwindSafe(|| {\n",
      "            struct Guard<'a, T: Future> {\n",
      "                core: &'a CoreStage<T>,\n",
      "            }\n",
      "\n",
      "            impl<T: Future> Drop for Guard<'_, T> {\n",
      "                fn drop(&mut self) {\n",
      "                    self.core.drop_future_or_output();\n",
      "                }\n",
      "            }\n",
      "\n",
      "            let guard = Guard { core };\n",
      "\n",
      "            let res = guard.core.poll(cx);\n",
      "\n",
      "            // prevent the guard from dropping the future\n",
      "            mem::forget(guard);\n",
      "\n",
      "            res\n",
      "        }));\n",
      "        match res {\n",
      "            Ok(Poll::Pending) => match header.state.transition_to_idle() {\n",
      "                Ok(snapshot) => {\n",
      "                    if snapshot.is_notified() {\n",
      "                        PollFuture::Notified\n",
      "                    } else {\n",
      "                        PollFuture::None\n",
      "                    }\n",
      "                }\n",
      "                Err(_) => PollFuture::Complete(Err(cancel_task(core)), true),\n",
      "            },\n",
      "            Ok(Poll::Ready(ok)) => PollFuture::Complete(Ok(ok), snapshot.is_join_interested()),\n",
      "            Err(err) => {\n",
      "                PollFuture::Complete(Err(JoinError::panic(err)), snapshot.is_join_interested())\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pysnooper\n",
    "\n",
    "file_path = file_paths[0]\n",
    "commit = dataset[0][\"base_commit\"]\n",
    "repo = dataset[0][\"repo\"]\n",
    "\n",
    "url = f\"{GITHUB_API_URL}/repos/{repo}/contents/{file_path}?ref={commit}\"\n",
    "headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "if access_token:\n",
    "    headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "\n",
    "# 获取文件内容\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to fetch file: {response.status_code} - {response.json()}\")\n",
    "\n",
    "# 解码文件内容 (Base64 编码)\n",
    "file_data = response.json()\n",
    "file_content = base64.b64decode(file_data[\"content\"]).decode(\"utf-8\")\n",
    "\n",
    "print(file_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

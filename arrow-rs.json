[
    {
        "repo": "apache/arrow-rs",
        "pull_number": 4681,
        "instance_id": "apache__arrow-rs-4681",
        "issue_numbers": [
            "4255"
        ],
        "base_commit": "c6184389241a0c85823aa494e8b5d93343771666",
        "patch": "diff --git a/arrow-array/src/array/list_array.rs b/arrow-array/src/array/list_array.rs\nindex 05628084c844..e50f2eb0941d 100644\n--- a/arrow-array/src/array/list_array.rs\n+++ b/arrow-array/src/array/list_array.rs\n@@ -1037,13 +1037,17 @@ mod tests {\n     #[should_panic(\n         expected = \"Memory pointer is not aligned with the specified scalar type\"\n     )]\n+    // Different error messages, so skip for now\n+    // https://github.com/apache/arrow-rs/issues/1545\n+    #[cfg(not(feature = \"force_validate\"))]\n     fn test_primitive_array_alignment() {\n         let buf = Buffer::from_slice_ref([0_u64]);\n         let buf2 = buf.slice(1);\n-        let array_data = ArrayData::builder(DataType::Int32)\n-            .add_buffer(buf2)\n-            .build()\n-            .unwrap();\n+        let array_data = unsafe {\n+            ArrayData::builder(DataType::Int32)\n+                .add_buffer(buf2)\n+                .build_unchecked()\n+        };\n         drop(Int32Array::from(array_data));\n     }\n \ndiff --git a/arrow-array/src/types.rs b/arrow-array/src/types.rs\nindex 769dbf974b93..d79b32a991ed 100644\n--- a/arrow-array/src/types.rs\n+++ b/arrow-array/src/types.rs\n@@ -1494,7 +1494,6 @@ pub type LargeBinaryType = GenericBinaryType<i64>;\n mod tests {\n     use super::*;\n     use arrow_data::{layout, BufferSpec};\n-    use std::mem::size_of;\n \n     #[test]\n     fn month_day_nano_should_roundtrip() {\n@@ -1541,7 +1540,8 @@ mod tests {\n         assert_eq!(\n             spec,\n             &BufferSpec::FixedWidth {\n-                byte_width: size_of::<T::Native>()\n+                byte_width: std::mem::size_of::<T::Native>(),\n+                alignment: std::mem::align_of::<T::Native>(),\n             }\n         );\n     }\ndiff --git a/arrow-data/src/data.rs b/arrow-data/src/data.rs\nindex 6ff8a824b2ff..0417e1d357c7 100644\n--- a/arrow-data/src/data.rs\n+++ b/arrow-data/src/data.rs\n@@ -20,7 +20,7 @@\n \n use crate::bit_iterator::BitSliceIterator;\n use arrow_buffer::buffer::{BooleanBuffer, NullBuffer};\n-use arrow_buffer::{bit_util, ArrowNativeType, Buffer, MutableBuffer};\n+use arrow_buffer::{bit_util, i256, ArrowNativeType, Buffer, MutableBuffer};\n use arrow_schema::{ArrowError, DataType, UnionMode};\n use std::convert::TryInto;\n use std::mem;\n@@ -451,7 +451,7 @@ impl ArrayData {\n \n         for spec in layout.buffers.iter() {\n             match spec {\n-                BufferSpec::FixedWidth { byte_width } => {\n+                BufferSpec::FixedWidth { byte_width, .. } => {\n                     let buffer_size =\n                         self.len.checked_mul(*byte_width).ok_or_else(|| {\n                             ArrowError::ComputeError(\n@@ -699,6 +699,23 @@ impl ArrayData {\n         Self::new_null(data_type, 0)\n     }\n \n+    /// Verifies that the buffers meet the minimum alignment requirements for the data type\n+    ///\n+    /// Buffers that are not adequately aligned will be copied to a new aligned allocation\n+    ///\n+    /// This can be useful for when interacting with data sent over IPC or FFI, that may\n+    /// not meet the minimum alignment requirements\n+    fn align_buffers(&mut self) {\n+        let layout = layout(&self.data_type);\n+        for (buffer, spec) in self.buffers.iter_mut().zip(&layout.buffers) {\n+            if let BufferSpec::FixedWidth { alignment, .. } = spec {\n+                if buffer.as_ptr().align_offset(*alignment) != 0 {\n+                    *buffer = Buffer::from_slice_ref(buffer.as_ref())\n+                }\n+            }\n+        }\n+    }\n+\n     /// \"cheap\" validation of an `ArrayData`. Ensures buffers are\n     /// sufficiently sized to store `len` + `offset` total elements of\n     /// `data_type` and performs other inexpensive consistency checks.\n@@ -736,10 +753,11 @@ impl ArrayData {\n             self.buffers.iter().zip(layout.buffers.iter()).enumerate()\n         {\n             match spec {\n-                BufferSpec::FixedWidth { byte_width } => {\n-                    let min_buffer_size = len_plus_offset\n-                        .checked_mul(*byte_width)\n-                        .expect(\"integer overflow computing min buffer size\");\n+                BufferSpec::FixedWidth {\n+                    byte_width,\n+                    alignment,\n+                } => {\n+                    let min_buffer_size = len_plus_offset.saturating_mul(*byte_width);\n \n                     if buffer.len() < min_buffer_size {\n                         return Err(ArrowError::InvalidArgumentError(format!(\n@@ -747,6 +765,14 @@ impl ArrayData {\n                             min_buffer_size, i, self.data_type, buffer.len()\n                         )));\n                     }\n+\n+                    let align_offset = buffer.as_ptr().align_offset(*alignment);\n+                    if align_offset != 0 {\n+                        return Err(ArrowError::InvalidArgumentError(format!(\n+                            \"Misaligned buffers[{i}] in array of type {:?}, offset from expected alignment of {alignment} by {}\",\n+                            self.data_type, align_offset.min(alignment - align_offset)\n+                        )));\n+                    }\n                 }\n                 BufferSpec::VariableWidth => {\n                     // not cheap to validate (need to look at the\n@@ -1493,7 +1519,8 @@ impl ArrayData {\n pub fn layout(data_type: &DataType) -> DataTypeLayout {\n     // based on C/C++ implementation in\n     // https://github.com/apache/arrow/blob/661c7d749150905a63dd3b52e0a04dac39030d95/cpp/src/arrow/type.h (and .cc)\n-    use std::mem::size_of;\n+    use arrow_schema::IntervalUnit::*;\n+\n     match data_type {\n         DataType::Null => DataTypeLayout {\n             buffers: vec![],\n@@ -1503,44 +1530,52 @@ pub fn layout(data_type: &DataType) -> DataTypeLayout {\n             buffers: vec![BufferSpec::BitMap],\n             can_contain_null_mask: true,\n         },\n-        DataType::Int8\n-        | DataType::Int16\n-        | DataType::Int32\n-        | DataType::Int64\n-        | DataType::UInt8\n-        | DataType::UInt16\n-        | DataType::UInt32\n-        | DataType::UInt64\n-        | DataType::Float16\n-        | DataType::Float32\n-        | DataType::Float64\n-        | DataType::Timestamp(_, _)\n-        | DataType::Date32\n-        | DataType::Date64\n-        | DataType::Time32(_)\n-        | DataType::Time64(_)\n-        | DataType::Interval(_) => {\n-            DataTypeLayout::new_fixed_width(data_type.primitive_width().unwrap())\n-        }\n-        DataType::Duration(_) => DataTypeLayout::new_fixed_width(size_of::<i64>()),\n-        DataType::Binary => DataTypeLayout::new_binary(size_of::<i32>()),\n-        DataType::FixedSizeBinary(bytes_per_value) => {\n-            let bytes_per_value: usize = (*bytes_per_value)\n-                .try_into()\n-                .expect(\"negative size for fixed size binary\");\n-            DataTypeLayout::new_fixed_width(bytes_per_value)\n+        DataType::Int8 => DataTypeLayout::new_fixed_width::<i8>(),\n+        DataType::Int16 => DataTypeLayout::new_fixed_width::<i16>(),\n+        DataType::Int32 => DataTypeLayout::new_fixed_width::<i32>(),\n+        DataType::Int64 => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::UInt8 => DataTypeLayout::new_fixed_width::<u8>(),\n+        DataType::UInt16 => DataTypeLayout::new_fixed_width::<u16>(),\n+        DataType::UInt32 => DataTypeLayout::new_fixed_width::<u32>(),\n+        DataType::UInt64 => DataTypeLayout::new_fixed_width::<u64>(),\n+        DataType::Float16 => DataTypeLayout::new_fixed_width::<half::f16>(),\n+        DataType::Float32 => DataTypeLayout::new_fixed_width::<f32>(),\n+        DataType::Float64 => DataTypeLayout::new_fixed_width::<f64>(),\n+        DataType::Timestamp(_, _) => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Date32 => DataTypeLayout::new_fixed_width::<i32>(),\n+        DataType::Date64 => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Time32(_) => DataTypeLayout::new_fixed_width::<i32>(),\n+        DataType::Time64(_) => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Interval(YearMonth) => DataTypeLayout::new_fixed_width::<i32>(),\n+        DataType::Interval(DayTime) => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Interval(MonthDayNano) => DataTypeLayout::new_fixed_width::<i128>(),\n+        DataType::Duration(_) => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Decimal128(_, _) => DataTypeLayout::new_fixed_width::<i128>(),\n+        DataType::Decimal256(_, _) => DataTypeLayout::new_fixed_width::<i256>(),\n+        DataType::FixedSizeBinary(size) => {\n+            let spec = BufferSpec::FixedWidth {\n+                byte_width: (*size).try_into().unwrap(),\n+                alignment: mem::align_of::<u8>(),\n+            };\n+            DataTypeLayout {\n+                buffers: vec![spec],\n+                can_contain_null_mask: true,\n+            }\n         }\n-        DataType::LargeBinary => DataTypeLayout::new_binary(size_of::<i64>()),\n-        DataType::Utf8 => DataTypeLayout::new_binary(size_of::<i32>()),\n-        DataType::LargeUtf8 => DataTypeLayout::new_binary(size_of::<i64>()),\n-        DataType::List(_) => DataTypeLayout::new_fixed_width(size_of::<i32>()),\n+        DataType::Binary => DataTypeLayout::new_binary::<i32>(),\n+        DataType::LargeBinary => DataTypeLayout::new_binary::<i64>(),\n+        DataType::Utf8 => DataTypeLayout::new_binary::<i32>(),\n+        DataType::LargeUtf8 => DataTypeLayout::new_binary::<i64>(),\n         DataType::FixedSizeList(_, _) => DataTypeLayout::new_empty(), // all in child data\n-        DataType::LargeList(_) => DataTypeLayout::new_fixed_width(size_of::<i64>()),\n+        DataType::List(_) => DataTypeLayout::new_fixed_width::<i32>(),\n+        DataType::LargeList(_) => DataTypeLayout::new_fixed_width::<i64>(),\n+        DataType::Map(_, _) => DataTypeLayout::new_fixed_width::<i32>(),\n         DataType::Struct(_) => DataTypeLayout::new_empty(), // all in child data,\n         DataType::RunEndEncoded(_, _) => DataTypeLayout::new_empty(), // all in child data,\n         DataType::Union(_, mode) => {\n             let type_ids = BufferSpec::FixedWidth {\n-                byte_width: size_of::<i8>(),\n+                byte_width: mem::size_of::<i8>(),\n+                alignment: mem::align_of::<i8>(),\n             };\n \n             DataTypeLayout {\n@@ -1552,7 +1587,8 @@ pub fn layout(data_type: &DataType) -> DataTypeLayout {\n                         vec![\n                             type_ids,\n                             BufferSpec::FixedWidth {\n-                                byte_width: size_of::<i32>(),\n+                                byte_width: mem::size_of::<i32>(),\n+                                alignment: mem::align_of::<i32>(),\n                             },\n                         ]\n                     }\n@@ -1561,19 +1597,6 @@ pub fn layout(data_type: &DataType) -> DataTypeLayout {\n             }\n         }\n         DataType::Dictionary(key_type, _value_type) => layout(key_type),\n-        DataType::Decimal128(_, _) => {\n-            // Decimals are always some fixed width; The rust implementation\n-            // always uses 16 bytes / size of i128\n-            DataTypeLayout::new_fixed_width(size_of::<i128>())\n-        }\n-        DataType::Decimal256(_, _) => {\n-            // Decimals are always some fixed width.\n-            DataTypeLayout::new_fixed_width(32)\n-        }\n-        DataType::Map(_, _) => {\n-            // same as ListType\n-            DataTypeLayout::new_fixed_width(size_of::<i32>())\n-        }\n     }\n }\n \n@@ -1589,10 +1612,13 @@ pub struct DataTypeLayout {\n }\n \n impl DataTypeLayout {\n-    /// Describes a basic numeric array where each element has a fixed width\n-    pub fn new_fixed_width(byte_width: usize) -> Self {\n+    /// Describes a basic numeric array where each element has type `T`\n+    pub fn new_fixed_width<T>() -> Self {\n         Self {\n-            buffers: vec![BufferSpec::FixedWidth { byte_width }],\n+            buffers: vec![BufferSpec::FixedWidth {\n+                byte_width: mem::size_of::<T>(),\n+                alignment: mem::align_of::<T>(),\n+            }],\n             can_contain_null_mask: true,\n         }\n     }\n@@ -1608,14 +1634,15 @@ impl DataTypeLayout {\n     }\n \n     /// Describes a basic numeric array where each element has a fixed\n-    /// with offset buffer of `offset_byte_width` bytes, followed by a\n+    /// with offset buffer of type `T`, followed by a\n     /// variable width data buffer\n-    pub fn new_binary(offset_byte_width: usize) -> Self {\n+    pub fn new_binary<T>() -> Self {\n         Self {\n             buffers: vec![\n                 // offsets\n                 BufferSpec::FixedWidth {\n-                    byte_width: offset_byte_width,\n+                    byte_width: mem::size_of::<T>(),\n+                    alignment: mem::align_of::<T>(),\n                 },\n                 // values\n                 BufferSpec::VariableWidth,\n@@ -1628,8 +1655,18 @@ impl DataTypeLayout {\n /// Layout specification for a single data type buffer\n #[derive(Debug, PartialEq, Eq)]\n pub enum BufferSpec {\n-    /// each element has a fixed width\n-    FixedWidth { byte_width: usize },\n+    /// Each element is a fixed width primitive, with the given `byte_width` and `alignment`\n+    ///\n+    /// `alignment` is the alignment required by Rust for an array of the corresponding primitive,\n+    /// see [`Layout::array`](std::alloc::Layout::array) and [`std::mem::align_of`].\n+    ///\n+    /// Arrow-rs requires that all buffers are have at least this alignment, to allow for\n+    /// [slice](std::slice) based APIs. We do not require alignment in excess of this to allow\n+    /// for array slicing, and interoperability with `Vec` which in the absence of support\n+    /// for custom allocators, cannot be over-aligned.\n+    ///\n+    /// Note that these alignment requirements will vary between architectures\n+    FixedWidth { byte_width: usize, alignment: usize },\n     /// Variable width, such as string data for utf8 data\n     VariableWidth,\n     /// Buffer holds a bitmap.\n@@ -1741,6 +1778,15 @@ impl ArrayDataBuilder {\n     /// apply.\n     #[allow(clippy::let_and_return)]\n     pub unsafe fn build_unchecked(self) -> ArrayData {\n+        let data = self.build_impl();\n+        // Provide a force_validate mode\n+        #[cfg(feature = \"force_validate\")]\n+        data.validate_data().unwrap();\n+        data\n+    }\n+\n+    /// Same as [`Self::build_unchecked`] but ignoring `force_validate` feature flag\n+    unsafe fn build_impl(self) -> ArrayData {\n         let nulls = self.nulls.or_else(|| {\n             let buffer = self.null_bit_buffer?;\n             let buffer = BooleanBuffer::new(buffer, self.offset, self.len);\n@@ -1750,26 +1796,41 @@ impl ArrayDataBuilder {\n             })\n         });\n \n-        let data = ArrayData {\n+        ArrayData {\n             data_type: self.data_type,\n             len: self.len,\n             offset: self.offset,\n             buffers: self.buffers,\n             child_data: self.child_data,\n             nulls: nulls.filter(|b| b.null_count() != 0),\n-        };\n-\n-        // Provide a force_validate mode\n-        #[cfg(feature = \"force_validate\")]\n-        data.validate_data().unwrap();\n-        data\n+        }\n     }\n \n     /// Creates an array data, validating all inputs\n-    #[allow(clippy::let_and_return)]\n     pub fn build(self) -> Result<ArrayData, ArrowError> {\n-        let data = unsafe { self.build_unchecked() };\n-        #[cfg(not(feature = \"force_validate\"))]\n+        let data = unsafe { self.build_impl() };\n+        data.validate_data()?;\n+        Ok(data)\n+    }\n+\n+    /// Creates an array data, validating all inputs, and aligning any buffers\n+    ///\n+    /// Rust requires that arrays are aligned to their corresponding primitive,\n+    /// see [`Layout::array`](std::alloc::Layout::array) and [`std::mem::align_of`].\n+    ///\n+    /// [`ArrayData`] therefore requires that all buffers are have at least this alignment,\n+    /// to allow for [slice](std::slice) based APIs. See [`BufferSpec::FixedWidth`].\n+    ///\n+    /// As this alignment is architecture specific, and not guaranteed by all arrow implementations,\n+    /// this method is provided to automatically copy buffers to a new correctly aligned allocation\n+    /// when necessary, making it useful when interacting with buffers produced by other systems,\n+    /// e.g. IPC or FFI.\n+    ///\n+    /// This is unlike `[Self::build`] which will instead return an error on encountering\n+    /// insufficiently aligned buffers.\n+    pub fn build_aligned(self) -> Result<ArrayData, ArrowError> {\n+        let mut data = unsafe { self.build_impl() };\n+        data.align_buffers();\n         data.validate_data()?;\n         Ok(data)\n     }\n@@ -2057,4 +2118,31 @@ mod tests {\n             assert_eq!(buffers.len(), layout.buffers.len());\n         }\n     }\n+\n+    #[test]\n+    fn test_alignment() {\n+        let buffer = Buffer::from_vec(vec![1_i32, 2_i32, 3_i32]);\n+        let sliced = buffer.slice(1);\n+\n+        let mut data = ArrayData {\n+            data_type: DataType::Int32,\n+            len: 0,\n+            offset: 0,\n+            buffers: vec![buffer],\n+            child_data: vec![],\n+            nulls: None,\n+        };\n+        data.validate_full().unwrap();\n+\n+        data.buffers[0] = sliced;\n+        let err = data.validate().unwrap_err();\n+\n+        assert_eq!(\n+            err.to_string(),\n+            \"Invalid argument error: Misaligned buffers[0] in array of type Int32, offset from expected alignment of 4 by 1\"\n+        );\n+\n+        data.align_buffers();\n+        data.validate_full().unwrap();\n+    }\n }\ndiff --git a/arrow-ipc/src/reader.rs b/arrow-ipc/src/reader.rs\nindex 0908d580d59a..b7d328977d1c 100644\n--- a/arrow-ipc/src/reader.rs\n+++ b/arrow-ipc/src/reader.rs\n@@ -20,7 +20,6 @@\n //! The `FileReader` and `StreamReader` have similar interfaces,\n //! however the `FileReader` expects a reader that supports `Seek`ing\n \n-use arrow_buffer::i256;\n use flatbuffers::VectorIter;\n use std::collections::HashMap;\n use std::fmt;\n@@ -129,7 +128,7 @@ fn create_array(reader: &mut ArrayReader, field: &Field) -> Result<ArrayRef, Arr\n                 .offset(0)\n                 .add_child_data(run_ends.into_data())\n                 .add_child_data(values.into_data())\n-                .build()?;\n+                .build_aligned()?;\n \n             Ok(make_array(data))\n         }\n@@ -202,7 +201,7 @@ fn create_array(reader: &mut ArrayReader, field: &Field) -> Result<ArrayRef, Arr\n             let data = ArrayData::builder(data_type.clone())\n                 .len(length as usize)\n                 .offset(0)\n-                .build()\n+                .build_aligned()\n                 .unwrap();\n             // no buffer increases\n             Ok(Arc::new(NullArray::from(data)))\n@@ -231,54 +230,17 @@ fn create_primitive_array(\n                 .len(length)\n                 .buffers(buffers[1..3].to_vec())\n                 .null_bit_buffer(null_buffer)\n-                .build()?\n+                .build_aligned()?\n         }\n-        Int8\n-        | Int16\n-        | Int32\n-        | UInt8\n-        | UInt16\n-        | UInt32\n-        | Time32(_)\n-        | Date32\n-        | Interval(IntervalUnit::YearMonth)\n-        | Interval(IntervalUnit::DayTime)\n-        | FixedSizeBinary(_)\n-        | Boolean\n-        | Int64\n-        | UInt64\n-        | Float32\n-        | Float64\n-        | Time64(_)\n-        | Timestamp(_, _)\n-        | Date64\n-        | Duration(_) => {\n+        _ if data_type.is_primitive()\n+            || matches!(data_type, Boolean | FixedSizeBinary(_)) =>\n+        {\n             // read 2 buffers: null buffer (optional) and data buffer\n             ArrayData::builder(data_type.clone())\n                 .len(length)\n                 .add_buffer(buffers[1].clone())\n                 .null_bit_buffer(null_buffer)\n-                .build()?\n-        }\n-        Interval(IntervalUnit::MonthDayNano) | Decimal128(_, _) => {\n-            let buffer = get_aligned_buffer::<i128>(&buffers[1], length);\n-\n-            // read 2 buffers: null buffer (optional) and data buffer\n-            ArrayData::builder(data_type.clone())\n-                .len(length)\n-                .add_buffer(buffer)\n-                .null_bit_buffer(null_buffer)\n-                .build()?\n-        }\n-        Decimal256(_, _) => {\n-            let buffer = get_aligned_buffer::<i256>(&buffers[1], length);\n-\n-            // read 2 buffers: null buffer (optional) and data buffer\n-            ArrayData::builder(data_type.clone())\n-                .len(length)\n-                .add_buffer(buffer)\n-                .null_bit_buffer(null_buffer)\n-                .build()?\n+                .build_aligned()?\n         }\n         t => unreachable!(\"Data type {:?} either unsupported or not primitive\", t),\n     };\n@@ -286,28 +248,10 @@ fn create_primitive_array(\n     Ok(make_array(array_data))\n }\n \n-/// Checks if given `Buffer` is properly aligned with `T`.\n-/// If not, copying the data and padded it for alignment.\n-fn get_aligned_buffer<T>(buffer: &Buffer, length: usize) -> Buffer {\n-    let ptr = buffer.as_ptr();\n-    let align_req = std::mem::align_of::<T>();\n-    let align_offset = ptr.align_offset(align_req);\n-    // The buffer is not aligned properly. The writer might use a smaller alignment\n-    // e.g. 8 bytes, but on some platform (e.g. ARM) i128 requires 16 bytes alignment.\n-    // We need to copy the buffer as fallback.\n-    if align_offset != 0 {\n-        let len_in_bytes = (length * std::mem::size_of::<T>()).min(buffer.len());\n-        let slice = &buffer.as_slice()[0..len_in_bytes];\n-        Buffer::from_slice_ref(slice)\n-    } else {\n-        buffer.clone()\n-    }\n-}\n-\n /// Reads the correct number of buffers based on list type and null_count, and creates a\n /// list array ref\n fn create_list_array(\n-    field_node: &crate::FieldNode,\n+    field_node: &FieldNode,\n     data_type: &DataType,\n     buffers: &[Buffer],\n     child_array: ArrayRef,\n@@ -329,13 +273,13 @@ fn create_list_array(\n \n         _ => unreachable!(\"Cannot create list or map array from {:?}\", data_type),\n     };\n-    Ok(make_array(builder.build()?))\n+    Ok(make_array(builder.build_aligned()?))\n }\n \n /// Reads the correct number of buffers based on list type and null_count, and creates a\n /// list array ref\n fn create_dictionary_array(\n-    field_node: &crate::FieldNode,\n+    field_node: &FieldNode,\n     data_type: &DataType,\n     buffers: &[Buffer],\n     value_array: ArrayRef,\n@@ -348,7 +292,7 @@ fn create_dictionary_array(\n             .add_child_data(value_array.into_data())\n             .null_bit_buffer(null_buffer);\n \n-        Ok(make_array(builder.build()?))\n+        Ok(make_array(builder.build_aligned()?))\n     } else {\n         unreachable!(\"Cannot create dictionary array from {:?}\", data_type)\n     }\n@@ -1097,10 +1041,11 @@ impl<R: Read> RecordBatchReader for StreamReader<R> {\n \n #[cfg(test)]\n mod tests {\n-    use crate::writer::unslice_run_array;\n+    use crate::writer::{unslice_run_array, DictionaryTracker, IpcDataGenerator};\n \n     use super::*;\n \n+    use crate::root_as_message;\n     use arrow_array::builder::{PrimitiveRunBuilder, UnionBuilder};\n     use arrow_array::types::*;\n     use arrow_buffer::ArrowNativeType;\n@@ -1357,8 +1302,7 @@ mod tests {\n         writer.finish().unwrap();\n         drop(writer);\n \n-        let mut reader =\n-            crate::reader::FileReader::try_new(std::io::Cursor::new(buf), None).unwrap();\n+        let mut reader = FileReader::try_new(std::io::Cursor::new(buf), None).unwrap();\n         reader.next().unwrap().unwrap()\n     }\n \n@@ -1704,4 +1648,40 @@ mod tests {\n         let output_batch = roundtrip_ipc_stream(&input_batch);\n         assert_eq!(input_batch, output_batch);\n     }\n+\n+    #[test]\n+    fn test_unaligned() {\n+        let batch = RecordBatch::try_from_iter(vec![(\n+            \"i32\",\n+            Arc::new(Int32Array::from(vec![1, 2, 3, 4])) as _,\n+        )])\n+        .unwrap();\n+\n+        let gen = IpcDataGenerator {};\n+        let mut dict_tracker = DictionaryTracker::new(false);\n+        let (_, encoded) = gen\n+            .encoded_batch(&batch, &mut dict_tracker, &Default::default())\n+            .unwrap();\n+\n+        let message = root_as_message(&encoded.ipc_message).unwrap();\n+\n+        // Construct an unaligned buffer\n+        let mut buffer = MutableBuffer::with_capacity(encoded.arrow_data.len() + 1);\n+        buffer.push(0_u8);\n+        buffer.extend_from_slice(&encoded.arrow_data);\n+        let b = Buffer::from(buffer).slice(1);\n+        assert_ne!(b.as_ptr().align_offset(8), 0);\n+\n+        let ipc_batch = message.header_as_record_batch().unwrap();\n+        let roundtrip = read_record_batch(\n+            &b,\n+            ipc_batch,\n+            batch.schema(),\n+            &Default::default(),\n+            None,\n+            &message.version(),\n+        )\n+        .unwrap();\n+        assert_eq!(batch, roundtrip);\n+    }\n }\ndiff --git a/arrow-ipc/src/writer.rs b/arrow-ipc/src/writer.rs\nindex 59657bc4be09..1c56613d8f24 100644\n--- a/arrow-ipc/src/writer.rs\n+++ b/arrow-ipc/src/writer.rs\n@@ -1146,7 +1146,7 @@ fn buffer_need_truncate(\n #[inline]\n fn get_buffer_element_width(spec: &BufferSpec) -> usize {\n     match spec {\n-        BufferSpec::FixedWidth { byte_width } => *byte_width,\n+        BufferSpec::FixedWidth { byte_width, .. } => *byte_width,\n         _ => 0,\n     }\n }\n",
        "test_patch": "diff --git a/arrow/tests/array_validation.rs b/arrow/tests/array_validation.rs\nindex 0d3652a0473a..fa80db1860cd 100644\n--- a/arrow/tests/array_validation.rs\n+++ b/arrow/tests/array_validation.rs\n@@ -56,7 +56,9 @@ fn test_bad_number_of_buffers() {\n }\n \n #[test]\n-#[should_panic(expected = \"integer overflow computing min buffer size\")]\n+#[should_panic(\n+    expected = \"Need at least 18446744073709551615 bytes in buffers[0] in array of type Int64, but got 8\"\n+)]\n fn test_fixed_width_overflow() {\n     let buffer = Buffer::from_slice_ref([0i32, 2i32]);\n     ArrayData::try_new(DataType::Int64, usize::MAX, None, 0, vec![buffer], vec![])\n",
        "problem_statement": "Handle Misaligned IPC Buffers\n**Is your feature request related to a problem or challenge? Please describe what you are trying to do.**\r\n<!--\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...] \r\n(This section helps Arrow developers understand the context and *why* for this feature, in addition to  the *what*)\r\n-->\r\n\r\nThe flatbuffer specification recommends that buffers are aligned to 64-bit boundaries, however, this is not mandated. Additionally when loading a flatbuffer from an in-memory source, it is possible the source buffer itself isn't aligned.\r\n\r\nWe already re-align interval buffers, we should do this consistently\r\n\r\n**Describe the solution you'd like**\r\n<!--\r\nA clear and concise description of what you want to happen.\r\n-->\r\n\r\nWe should automatically re-align mis-aligned IPC buffers\r\n\r\n**Describe alternatives you've considered**\r\n<!--\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n-->\r\n\r\n**Additional context**\r\n<!--\r\nAdd any other context or screenshots about the feature request here.\r\n-->\r\n\r\nRelates to #4254 which would likely produce mis-aligned buffers\r\n\n",
        "hints_text": "",
        "created_at": "2023-08-11T11:00:40Z",
        "version": "45.0",
        "environment_setup_commit": "c6184389241a0c85823aa494e8b5d93343771666",
        "FAIL_TO_PASS": [
            "test_fixed_width_overflow - should panic"
        ],
        "PASS_TO_PASS": [
            "arrow/src/lib.rs - (line 108)",
            "arrow/src/lib.rs - (line 89)",
            "arrow/src/lib.rs - (line 221)",
            "arrow/src/lib.rs - (line 65)",
            "arrow/src/lib.rs - (line 31)",
            "arrow/src/lib.rs - (line 195)",
            "arrow/src/lib.rs - (line 250)",
            "arrow/src/lib.rs - (line 46)",
            "arrow/src/lib.rs - (line 129)",
            "arrow/src/util/string_writer.rs - util::string_writer (line 25)",
            "arrow/src/lib.rs - (line 166)",
            "test_bad_number_of_buffers - should panic",
            "test_bitmap_too_small - should panic",
            "test_buffer_too_small - should panic",
            "test_buffer_too_small_offset - should panic",
            "test_decimal_full_validation",
            "test_decimal_validation",
            "test_empty_large_utf8_array_with_wrong_type_offsets - should panic",
            "test_empty_utf8_array_with_empty_offsets_buffer",
            "test_empty_utf8_array_with_invalid_offset - should panic",
            "test_empty_utf8_array_with_non_zero_offset",
            "test_empty_utf8_array_with_single_zero_offset",
            "test_mismatched_dictionary_types - should panic",
            "test_non_int_dictionary - should panic",
            "test_sliced_array_child",
            "test_string_data_from_foreign",
            "test_try_new_sliced_struct",
            "test_validate_binary_out_of_bounds - should panic",
            "test_validate_binary_index_backwards - should panic",
            "test_validate_dictionary_index_giant_negative - should panic",
            "test_validate_dictionary_index_negative_but_not_referenced",
            "test_validate_dictionary_index_negative - should panic",
            "test_validate_fixed_size_list - should panic",
            "test_validate_dictionary_index_too_large - should panic",
            "test_validate_large_binary_index_backwards - should panic",
            "test_validate_large_binary_out_of_bounds - should panic",
            "test_validate_large_list_offsets - should panic",
            "test_validate_large_utf8_char_boundary - should panic",
            "test_validate_large_utf8_content - should panic",
            "test_validate_large_utf8_index_backwards - should panic",
            "test_validate_large_utf8_out_of_bounds - should panic",
            "test_validate_list_negative_offsets - should panic",
            "test_validate_list_offsets - should panic",
            "test_validate_offsets_first_too_large - should panic",
            "test_validate_offsets_first_too_large_skipped",
            "test_validate_offsets_i32 - should panic",
            "test_validate_offsets_i64 - should panic",
            "test_validate_offsets_last_too_large - should panic",
            "test_validate_offsets_negative_first_i32 - should panic",
            "test_validate_offsets_negative_last_i32 - should panic",
            "test_validate_offsets_range_too_large - should panic",
            "test_validate_offsets_range_too_small - should panic",
            "test_validate_struct_child_length - should panic",
            "test_validate_struct_child_type - should panic",
            "test_validate_union_dense_with_bad_len - should panic",
            "test_validate_union_dense_without_offsets - should panic",
            "test_validate_union_different_types - should panic",
            "test_validate_union_sparse_different_child_len - should panic",
            "test_validate_utf8_char_boundary - should panic",
            "test_validate_utf8_content - should panic",
            "test_validate_utf8_index_backwards - should panic",
            "test_validate_utf8_out_of_bounds - should panic"
        ],
        "FAIL_TO_FAIL": [],
        "PASS_TO_FAIL": []
    },
    {
        "repo": "apache/arrow-rs",
        "pull_number": 4670,
        "instance_id": "apache__arrow-rs-4670",
        "issue_numbers": [
            "4637"
        ],
        "base_commit": "5023ea8438e3143bf711a89a3a2ffb8838a18e9e",
        "patch": "diff --git a/arrow-data/src/equal/fixed_binary.rs b/arrow-data/src/equal/fixed_binary.rs\nindex 9e0e77ff7eca..40dacdddd3a0 100644\n--- a/arrow-data/src/equal/fixed_binary.rs\n+++ b/arrow-data/src/equal/fixed_binary.rs\n@@ -80,7 +80,7 @@ pub(super) fn fixed_binary_equal(\n                 lhs_start + lhs_nulls.offset(),\n                 len,\n             );\n-            let rhs_nulls = lhs.nulls().unwrap();\n+            let rhs_nulls = rhs.nulls().unwrap();\n             let rhs_slices_iter = BitSliceIterator::new(\n                 rhs_nulls.validity(),\n                 rhs_start + rhs_nulls.offset(),\n",
        "test_patch": "diff --git a/arrow/tests/array_equal.rs b/arrow/tests/array_equal.rs\nindex 83a280db67b8..4abe31a36cf5 100644\n--- a/arrow/tests/array_equal.rs\n+++ b/arrow/tests/array_equal.rs\n@@ -1295,3 +1295,25 @@ fn test_struct_equal_slice() {\n \n     test_equal(&a, &b, true);\n }\n+\n+#[test]\n+fn test_list_excess_children_equal() {\n+    let mut a = ListBuilder::new(FixedSizeBinaryBuilder::new(5));\n+    a.values().append_value(b\"11111\").unwrap(); // Masked value\n+    a.append_null();\n+    a.values().append_value(b\"22222\").unwrap();\n+    a.values().append_null();\n+    a.append(true);\n+    let a = a.finish();\n+\n+    let mut b = ListBuilder::new(FixedSizeBinaryBuilder::new(5));\n+    b.append_null();\n+    b.values().append_value(b\"22222\").unwrap();\n+    b.values().append_null();\n+    b.append(true);\n+    let b = b.finish();\n+\n+    assert_eq!(a.value_offsets(), &[0, 1, 3]);\n+    assert_eq!(b.value_offsets(), &[0, 0, 2]);\n+    assert_eq!(a, b);\n+}\n",
        "problem_statement": "`List(FixedSizeBinary)` array equality check may return wrong result\n**Describe the bug**\r\n`<ListArray as PartialEq>::eq` returns `false` for two arrays of datatype `List(FixedSizeBinary(5))` containing identical values but physically differ.\r\n\r\n**To Reproduce**\r\n```rust\r\n#[test]\r\nfn test_list_excess_children_equal() {\r\n    let a_values = create_fixed_size_binary_array([Some(b\"11111\"), Some(b\"22222\"), None]);\r\n    //                                             ^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^\r\n    //                                             a[0]            a[1]\r\n    let a: ListArray = ArrayDataBuilder::new(DataType::List(Arc::new(Field::new(\r\n        \"item\",\r\n        a_values.data_type().clone(),\r\n        true,\r\n    ))))\r\n    .len(2)\r\n    .add_buffer(Buffer::from(vec![0i32, 1, 3].to_byte_slice()))\r\n    .add_child_data(a_values.into_data())\r\n    .null_bit_buffer(Some(Buffer::from(&[0b00000010])))\r\n    .build()\r\n    .unwrap()\r\n    .into();\r\n\r\n    let b_values = create_fixed_size_binary_array([Some(b\"22222\"), None]);\r\n    //                                             ^^^^^^^^^^^^^^^^^^^^\r\n    //                                             a[1]\r\n    let b: ListArray = ArrayDataBuilder::new(DataType::List(Arc::new(Field::new(\r\n        \"item\",\r\n        b_values.data_type().clone(),\r\n        true,\r\n    ))))\r\n    .len(2)\r\n    .add_buffer(Buffer::from(vec![0i32, 0, 2].to_byte_slice()))\r\n    .add_child_data(b_values.into_data())\r\n    .null_bit_buffer(Some(Buffer::from(&[0b00000010])))\r\n    .build()\r\n    .unwrap()\r\n    .into();\r\n\r\n    a.to_data().validate_full().unwrap();\r\n    b.to_data().validate_full().unwrap();\r\n\r\n    assert_eq!(a, b);\r\n}\r\n\r\n// from `arrow/tests/array_equal.rs`\r\nfn create_fixed_size_binary_array<U: AsRef<[u8]>, T: AsRef<[Option<U>]>>(\r\n    data: T,\r\n) -> FixedSizeBinaryArray {\r\n    let mut builder = FixedSizeBinaryBuilder::with_capacity(data.as_ref().len(), 5);\r\n\r\n    for d in data.as_ref() {\r\n        if let Some(v) = d {\r\n            builder.append_value(v.as_ref()).unwrap();\r\n        } else {\r\n            builder.append_null();\r\n        }\r\n    }\r\n    builder.finish()\r\n}\r\n```\r\n\r\n```\r\nthread 'test_list_excess_children_equal' panicked at 'assertion failed: `(left == right)`\r\n  left: `ListArray\r\n[\r\n  null,\r\n  FixedSizeBinaryArray<5>\r\n[\r\n  [50, 50, 50, 50, 50],\r\n  null,\r\n],\r\n]`,\r\n right: `ListArray\r\n[\r\n  null,\r\n  FixedSizeBinaryArray<5>\r\n[\r\n  [50, 50, 50, 50, 50],\r\n  null,\r\n],\r\n]`', arrow\\tests\\array_equal.rs:399:5\r\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\r\n```\r\n\r\n**Expected behavior**\r\nReturning `true` because they both contain `[null, [[50, 50, 50, 50, 50], null]]` as shown by the debug printing\r\n\r\n**Additional context**\r\n<!--\r\nAdd any other context about the problem here.\r\n-->\n",
        "hints_text": "These two array isn't equal in fact.\r\n\r\n```\r\nvalues: [\r\n  [49, 49, 49, 49, 49],\r\n  [50, 50, 50, 50, 50],\r\n  null,\r\n]\r\nvalue_offsets: [0, 1, 3]\r\n\r\nvalues [\r\n  [50, 50, 50, 50, 50],\r\n  null,\r\n]\r\nvalue_offsets [0, 0, 2]\r\n\r\n```",
        "created_at": "2023-08-09T15:59:12Z",
        "version": "45.0",
        "environment_setup_commit": "c6184389241a0c85823aa494e8b5d93343771666",
        "FAIL_TO_PASS": [
            "test_list_excess_children_equal"
        ],
        "PASS_TO_PASS": [
            "arrow/src/lib.rs - (line 108)",
            "arrow/src/lib.rs - (line 89)",
            "arrow/src/lib.rs - (line 221)",
            "arrow/src/lib.rs - (line 65)",
            "arrow/src/lib.rs - (line 31)",
            "arrow/src/lib.rs - (line 195)",
            "arrow/src/lib.rs - (line 46)",
            "arrow/src/lib.rs - (line 250)",
            "arrow/src/lib.rs - (line 129)",
            "arrow/src/util/string_writer.rs - util::string_writer (line 25)",
            "arrow/src/lib.rs - (line 166)",
            "test_binary_equal",
            "list_array_non_zero_nulls",
            "test_boolean_equal_nulls",
            "test_boolean_slice",
            "test_boolean_equal_offset",
            "test_boolean_equal",
            "test_decimal_offsets",
            "test_decimal_null",
            "test_decimal_equal",
            "test_dictionary_equal",
            "test_empty_offsets_list_equal",
            "test_dictionary_equal_null",
            "test_fixed_list_null",
            "test_fixed_size_binary_equal",
            "test_fixed_size_binary_array",
            "test_fixed_size_binary_null",
            "test_fixed_size_binary_offsets",
            "test_fixed_list_offsets",
            "test_fixed_size_list_equal",
            "test_large_binary_equal",
            "test_large_string_equal",
            "test_list_different_offsets",
            "test_list_equal",
            "test_list_null",
            "test_non_null_empty_strings",
            "test_list_offsets",
            "test_null",
            "test_null_empty_strings",
            "test_null_equal",
            "test_primitive",
            "test_primitive_slice",
            "test_sliced_nullable_boolean_array",
            "test_string_equal",
            "test_string_offset",
            "test_string_offset_larger",
            "test_struct_equal",
            "test_struct_equal_slice",
            "test_struct_equal_null_variable_size",
            "test_struct_equal_null",
            "test_union_equal_sparse_slice",
            "test_union_equal_sparse",
            "test_union_equal_dense"
        ],
        "FAIL_TO_FAIL": [],
        "PASS_TO_FAIL": []
    },
    {
        "repo": "apache/arrow-rs",
        "pull_number": 4598,
        "instance_id": "apache__arrow-rs-4598",
        "issue_numbers": [
            "4578"
        ],
        "base_commit": "95683439fa4108c036e48b334f8bed898b87a9b9",
        "patch": "diff --git a/arrow-data/src/transform/union.rs b/arrow-data/src/transform/union.rs\nindex 8d1ea34c314d..d7083588d782 100644\n--- a/arrow-data/src/transform/union.rs\n+++ b/arrow-data/src/transform/union.rs\n@@ -39,6 +39,9 @@ pub(super) fn build_extend_sparse(array: &ArrayData) -> Extend {\n pub(super) fn build_extend_dense(array: &ArrayData) -> Extend {\n     let type_ids = array.buffer::<i8>(0);\n     let offsets = array.buffer::<i32>(1);\n+    let arrow_schema::DataType::Union(src_fields, _) = array.data_type() else {\n+        unreachable!();\n+    };\n \n     Box::new(\n         move |mutable: &mut _MutableArrayData, index: usize, start: usize, len: usize| {\n@@ -48,14 +51,18 @@ pub(super) fn build_extend_dense(array: &ArrayData) -> Extend {\n                 .extend_from_slice(&type_ids[start..start + len]);\n \n             (start..start + len).for_each(|i| {\n-                let type_id = type_ids[i] as usize;\n+                let type_id = type_ids[i];\n+                let child_index = src_fields\n+                    .iter()\n+                    .position(|(r, _)| r == type_id)\n+                    .expect(\"invalid union type ID\");\n                 let src_offset = offsets[i] as usize;\n-                let child_data = &mut mutable.child_data[type_id];\n+                let child_data = &mut mutable.child_data[child_index];\n                 let dst_offset = child_data.len();\n \n                 // Extend offsets\n                 mutable.buffer2.push(dst_offset as i32);\n-                mutable.child_data[type_id].extend(index, src_offset, src_offset + 1)\n+                mutable.child_data[child_index].extend(index, src_offset, src_offset + 1)\n             })\n         },\n     )\n",
        "test_patch": "diff --git a/arrow/tests/array_transform.rs b/arrow/tests/array_transform.rs\nindex ebbadc00aecd..15141eb208e4 100644\n--- a/arrow/tests/array_transform.rs\n+++ b/arrow/tests/array_transform.rs\n@@ -19,7 +19,7 @@ use arrow::array::{\n     Array, ArrayRef, BooleanArray, Decimal128Array, DictionaryArray,\n     FixedSizeBinaryArray, Int16Array, Int32Array, Int64Array, Int64Builder, ListArray,\n     ListBuilder, MapBuilder, NullArray, StringArray, StringBuilder,\n-    StringDictionaryBuilder, StructArray, UInt8Array,\n+    StringDictionaryBuilder, StructArray, UInt8Array, UnionArray,\n };\n use arrow::datatypes::Int16Type;\n use arrow_buffer::Buffer;\n@@ -488,6 +488,63 @@ fn test_struct_many() {\n     assert_eq!(array, expected)\n }\n \n+#[test]\n+fn test_union_dense() {\n+    // Input data\n+    let strings: ArrayRef = Arc::new(StringArray::from(vec![\n+        Some(\"joe\"),\n+        Some(\"mark\"),\n+        Some(\"doe\"),\n+    ]));\n+    let ints: ArrayRef = Arc::new(Int32Array::from(vec![\n+        Some(1),\n+        Some(2),\n+        Some(3),\n+        Some(4),\n+        Some(5),\n+    ]));\n+    let offsets = Buffer::from_slice_ref([0, 0, 1, 1, 2, 2, 3, 4i32]);\n+    let type_ids = Buffer::from_slice_ref([42, 84, 42, 84, 84, 42, 84, 84i8]);\n+\n+    let array = UnionArray::try_new(\n+        &[84, 42],\n+        type_ids,\n+        Some(offsets),\n+        vec![\n+            (Field::new(\"int\", DataType::Int32, false), ints),\n+            (Field::new(\"string\", DataType::Utf8, false), strings),\n+        ],\n+    )\n+    .unwrap()\n+    .into_data();\n+    let arrays = vec![&array];\n+    let mut mutable = MutableArrayData::new(arrays, false, 0);\n+\n+    // Slice it by `MutableArrayData`\n+    mutable.extend(0, 4, 7);\n+    let data = mutable.freeze();\n+    let array = UnionArray::from(data);\n+\n+    // Expected data\n+    let strings: ArrayRef = Arc::new(StringArray::from(vec![Some(\"doe\")]));\n+    let ints: ArrayRef = Arc::new(Int32Array::from(vec![Some(3), Some(4)]));\n+    let offsets = Buffer::from_slice_ref([0, 0, 1i32]);\n+    let type_ids = Buffer::from_slice_ref([84, 42, 84i8]);\n+\n+    let expected = UnionArray::try_new(\n+        &[84, 42],\n+        type_ids,\n+        Some(offsets),\n+        vec![\n+            (Field::new(\"int\", DataType::Int32, false), ints),\n+            (Field::new(\"string\", DataType::Utf8, false), strings),\n+        ],\n+    )\n+    .unwrap();\n+\n+    assert_eq!(array.to_data(), expected.to_data());\n+}\n+\n #[test]\n fn test_binary_fixed_sized_offsets() {\n     let array = FixedSizeBinaryArray::try_from_iter(\n",
        "problem_statement": "`arrow::compute::concat` panics for dense union arrays with non-trivial type IDs\n**Describe the bug**\r\n`arrow::compute::concat` panics when called with dense union arrays with type IDs that don't start at zero.\r\n\r\n```\r\nthread 'proptest::tests::qc_row' panicked at 'index out of bounds: the len is 1 but the index is 35', ...\\.cargo\\registry\\src\\index.crates.io-6f17d22bba15001f\\arrow-data-43.0.0\\src\\transform\\union.rs:53:39\r\nstack backtrace:\r\n ...\r\n   3: arrow_data::transform::union::build_extend_dense::{{closure}}::{{closure}}\r\n   4: core::iter::traits::iterator::Iterator::for_each::call::{{closure}}\r\n             at /rustc/864bdf7843e1ceabc824ed86d97006acad6af643\\library\\core\\src\\iter\\traits/iterator.rs:853:29\r\n   5: core::iter::traits::iterator::Iterator::fold\r\n             at /rustc/864bdf7843e1ceabc824ed86d97006acad6af643\\library\\core\\src\\iter\\traits/iterator.rs:2481:21\r\n   6: core::iter::traits::iterator::Iterator::for_each\r\n             at /rustc/864bdf7843e1ceabc824ed86d97006acad6af643\\library\\core\\src\\iter\\traits/iterator.rs:856:9\r\n   7: arrow_data::transform::union::build_extend_dense::{{closure}}\r\n             at ...\\.cargo\\registry\\src\\index.crates.io-6f17d22bba15001f\\arrow-data-43.0.0\\src\\transform\\union.rs:50:13\r\n   8: <alloc::boxed::Box<F,A> as core::ops::function::Fn<Args>>::call\r\n             at /rustc/864bdf7843e1ceabc824ed86d97006acad6af643\\library\\alloc\\src/boxed.rs:2021:9\r\n   9: arrow_data::transform::MutableArrayData::extend\r\n             at ...\\.cargo\\registry\\src\\index.crates.io-6f17d22bba15001f\\arrow-data-43.0.0\\src\\transform\\mod.rs:631:9\r\n  10: arrow_select::concat::concat\r\n             at ...\\.cargo\\registry\\src\\index.crates.io-6f17d22bba15001f\\arrow-select-43.0.0\\src\\concat.rs:89:9\r\n```\r\n\r\n**To Reproduce**\r\n\r\nCall `arrow::compute::concat` and pass the following arrays:\r\n\r\n    [\r\n        UnionArray(Dense)\r\n        [\r\n            -- type id buffer:\r\n            ScalarBuffer([35])\r\n            -- offsets buffer:\r\n            ScalarBuffer([0])\r\n            -- child 35: \"\" (Null)\r\n            NullArray(1)\r\n        ],\r\n        UnionArray(Dense)\r\n        [\r\n            -- type id buffer:\r\n            ScalarBuffer([35])\r\n            -- offsets buffer:\r\n            ScalarBuffer([0])\r\n            -- child 35: \"\" (Null)\r\n            NullArray(1)\r\n        ],\r\n    ]\r\n\r\nof the following data type:\r\n\r\n\r\n```\r\nUnion(\r\n    [\r\n        (\r\n            35,\r\n            Field {\r\n                name: \"\",\r\n                data_type: Null,\r\n                nullable: false,\r\n                dict_id: 0,\r\n                dict_is_ordered: false,\r\n                metadata: {},\r\n            },\r\n        ),\r\n    ],\r\n    Dense,\r\n)\r\n```\r\n\r\n**Expected behavior**\r\n\r\nProducing the following array:\r\n\r\n```\r\nUnionArray(Dense)\r\n[\r\n    -- type id buffer:\r\n    ScalarBuffer([35, 35])\r\n    -- offsets buffer:\r\n    ScalarBuffer([0, 1])\r\n    -- child 35: \"\" (Null)\r\n    NullArray(2)\r\n]\r\n```\r\n\r\n\r\n**Additional context**\r\n<!--\r\nAdd any other context about the problem here.\r\n-->\n",
        "hints_text": "MutableArrayData likely needs to be updated to properly understand UnionArray with non-trivial type ids",
        "created_at": "2023-07-31T04:27:18Z",
        "version": "45.0",
        "environment_setup_commit": "c6184389241a0c85823aa494e8b5d93343771666",
        "FAIL_TO_PASS": [
            "test_union_dense"
        ],
        "PASS_TO_PASS": [
            "arrow/src/lib.rs - (line 108)",
            "arrow/src/lib.rs - (line 89)",
            "arrow/src/lib.rs - (line 221)",
            "arrow/src/lib.rs - (line 65)",
            "arrow/src/lib.rs - (line 31)",
            "arrow/src/lib.rs - (line 195)",
            "arrow/src/lib.rs - (line 46)",
            "arrow/src/lib.rs - (line 250)",
            "arrow/src/util/string_writer.rs - util::string_writer (line 25)",
            "arrow/src/lib.rs - (line 129)",
            "arrow/src/lib.rs - (line 166)",
            "test_binary_fixed_sized_offsets",
            "test_bool",
            "test_decimal_null_offset_nulls",
            "test_decimal_offset",
            "test_decimal",
            "test_extend_nulls",
            "test_dictionary",
            "test_extend_nulls_panic - should panic",
            "test_fixed_size_binary_append",
            "test_list_append",
            "test_list_null_offset",
            "test_list_nulls_append",
            "test_list_of_strings_append",
            "test_multiple_with_nulls",
            "test_null",
            "test_map_nulls_append",
            "test_primitive",
            "test_primitive_null_offset",
            "test_primitive_null_offset_nulls",
            "test_primitive_offset",
            "test_string_offsets",
            "test_string_null_offset_nulls",
            "test_struct",
            "test_struct_many",
            "test_struct_nulls",
            "test_struct_offset",
            "test_variable_sized_nulls",
            "test_variable_sized_offsets"
        ],
        "FAIL_TO_FAIL": [],
        "PASS_TO_FAIL": []
    },
    {
        "repo": "apache/arrow-rs",
        "pull_number": 5439,
        "instance_id": "apache__arrow-rs-5439",
        "issue_numbers": [
            "5438"
        ],
        "base_commit": "ef5c45cf4186a8124da5a1603ebdbc09ef9928fc",
        "patch": "diff --git a/arrow-flight/src/error.rs b/arrow-flight/src/error.rs\nindex e054883e965d..ba979ca9f7a6 100644\n--- a/arrow-flight/src/error.rs\n+++ b/arrow-flight/src/error.rs\n@@ -49,17 +49,24 @@ impl FlightError {\n \n impl std::fmt::Display for FlightError {\n     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n-        // TODO better format / error\n-        write!(f, \"{self:?}\")\n+        match self {\n+            FlightError::Arrow(source) => write!(f, \"Arrow error: {}\", source),\n+            FlightError::NotYetImplemented(desc) => write!(f, \"Not yet implemented: {}\", desc),\n+            FlightError::Tonic(source) => write!(f, \"Tonic error: {}\", source),\n+            FlightError::ProtocolError(desc) => write!(f, \"Protocol error: {}\", desc),\n+            FlightError::DecodeError(desc) => write!(f, \"Decode error: {}\", desc),\n+            FlightError::ExternalError(source) => write!(f, \"External error: {}\", source),\n+        }\n     }\n }\n \n impl Error for FlightError {\n     fn source(&self) -> Option<&(dyn Error + 'static)> {\n-        if let Self::ExternalError(e) = self {\n-            Some(e.as_ref())\n-        } else {\n-            None\n+        match self {\n+            FlightError::Arrow(source) => Some(source),\n+            FlightError::Tonic(source) => Some(source),\n+            FlightError::ExternalError(source) => Some(source.as_ref()),\n+            _ => None,\n         }\n     }\n }\ndiff --git a/arrow-schema/src/error.rs b/arrow-schema/src/error.rs\nindex b7bf8d6e12a6..d9a0f3452c86 100644\n--- a/arrow-schema/src/error.rs\n+++ b/arrow-schema/src/error.rs\n@@ -114,10 +114,10 @@ impl Display for ArrowError {\n \n impl Error for ArrowError {\n     fn source(&self) -> Option<&(dyn Error + 'static)> {\n-        if let Self::ExternalError(e) = self {\n-            Some(e.as_ref())\n-        } else {\n-            None\n+        match self {\n+            ArrowError::ExternalError(source) => Some(source.as_ref()),\n+            ArrowError::IoError(_, source) => Some(source),\n+            _ => None,\n         }\n     }\n }\n",
        "test_patch": "diff --git a/arrow-flight/tests/client.rs b/arrow-flight/tests/client.rs\nindex 9e19bce92338..47565334cb63 100644\n--- a/arrow-flight/tests/client.rs\n+++ b/arrow-flight/tests/client.rs\n@@ -935,7 +935,7 @@ async fn test_cancel_flight_info_error_no_response() {\n \n         assert_eq!(\n             err.to_string(),\n-            \"ProtocolError(\\\"Received no response for cancel_flight_info call\\\")\"\n+            \"Protocol error: Received no response for cancel_flight_info call\"\n         );\n         // server still got the request\n         let expected_request = Action::new(\"CancelFlightInfo\", request.encode_to_vec());\n@@ -985,7 +985,7 @@ async fn test_renew_flight_endpoint_error_no_response() {\n \n         assert_eq!(\n             err.to_string(),\n-            \"ProtocolError(\\\"Received no response for renew_flight_endpoint call\\\")\"\n+            \"Protocol error: Received no response for renew_flight_endpoint call\"\n         );\n         // server still got the request\n         let expected_request = Action::new(\"RenewFlightEndpoint\", request.encode_to_vec());\ndiff --git a/arrow-flight/tests/encode_decode.rs b/arrow-flight/tests/encode_decode.rs\nindex f4741d743e57..789233b918d0 100644\n--- a/arrow-flight/tests/encode_decode.rs\n+++ b/arrow-flight/tests/encode_decode.rs\n@@ -57,7 +57,7 @@ async fn test_error() {\n     let result: Result<Vec<_>, _> = decode_stream.try_collect().await;\n \n     let result = result.unwrap_err();\n-    assert_eq!(result.to_string(), r#\"NotYetImplemented(\"foo\")\"#);\n+    assert_eq!(result.to_string(), \"Not yet implemented: foo\");\n }\n \n #[tokio::test]\n@@ -287,7 +287,7 @@ async fn test_mismatched_record_batch_schema() {\n     let err = result.unwrap_err();\n     assert_eq!(\n         err.to_string(),\n-        \"Arrow(InvalidArgumentError(\\\"number of columns(1) must match number of fields(2) in schema\\\"))\"\n+        \"Arrow error: Invalid argument error: number of columns(1) must match number of fields(2) in schema\"\n     );\n }\n \n@@ -312,7 +312,7 @@ async fn test_chained_streams_batch_decoder() {\n     let err = result.unwrap_err();\n     assert_eq!(\n         err.to_string(),\n-        \"ProtocolError(\\\"Unexpectedly saw multiple Schema messages in FlightData stream\\\")\"\n+        \"Protocol error: Unexpectedly saw multiple Schema messages in FlightData stream\"\n     );\n }\n \n",
        "problem_statement": "Refine `Display` implementation for `FlightError`\n**Is your feature request related to a problem or challenge? Please describe what you are trying to do.**\r\n\r\nThere's a `TODO` for a better `std::fmt::Display` implementation on `FlightError`. Currently it forwards to `std::fmt::Debug`, which does not appear to be a good practice as errors should describe themselves with friendly messages provided by `Display`.\r\n\r\nhttps://github.com/apache/arrow-rs/blob/ef5c45cf4186a8124da5a1603ebdbc09ef9928fc/arrow-flight/src/error.rs#L50-L55\r\n\r\n**Describe the solution you'd like**\r\n\r\nMatch the variants of the error and specify different prompts like what we did for `ArrowError`.\r\n\r\nhttps://github.com/apache/arrow-rs/blob/ef5c45cf4186a8124da5a1603ebdbc09ef9928fc/arrow-schema/src/error.rs#L79-L87\r\n\r\n**Describe alternatives you've considered**\r\n\r\nDerive the implementation with `thiserror`. The code can be more concise with the cost of introducing a new build-time dependency.\r\n\r\n**Additional context**\r\n\r\nA better practice to implement `Display` for errors is **NOT** to include the error source. AWS SDK has adopted this as described in https://github.com/awslabs/aws-sdk-rust/issues/657. However, this could be considered as a breaking change as many developers have not realize that one should leverage something like [`std::error::Report`](https://doc.rust-lang.org/stable/std/error/struct.Report.html) to get the error sources printed.\n",
        "hints_text": "",
        "created_at": "2024-02-27T07:27:28Z",
        "version": "50.0",
        "environment_setup_commit": "82fc0df73ab97e239ce5c748a05c57ce582f3d5d",
        "FAIL_TO_PASS": [
            "test_cancel_flight_info_error_no_response",
            "test_renew_flight_endpoint_error_no_response",
            "test_error",
            "test_chained_streams_batch_decoder",
            "test_mismatched_record_batch_schema"
        ],
        "PASS_TO_PASS": [
            "arrow-flight/src/client.rs - client::FlightClient::get_schema (line 497) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::cancel_flight_info (line 609) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::do_get (line 182) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::do_action (line 564) - compile",
            "arrow-flight/src/client.rs - client::FlightClient (line 49) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::list_flights (line 454) - compile",
            "arrow-flight/src/encode.rs - encode::FlightDataEncoderBuilder (line 46) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::poll_flight_info (line 283) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::list_actions (line 529) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::do_put (line 335) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::get_flight_info (line 227) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::do_exchange (line 404) - compile",
            "arrow-flight/src/client.rs - client::FlightClient::renew_flight_endpoint (line 647) - compile",
            "arrow-flight/src/decode.rs - decode::FlightRecordBatchStream (line 39) - compile",
            "arrow-flight/src/encode.rs - encode::FlightDataEncoderBuilder (line 74)",
            "arrow-flight/src/lib.rs - FlightData::new (line 461)",
            "arrow-flight/src/lib.rs - Ticket::new (line 745)",
            "arrow-flight/src/lib.rs - PollInfo::new (line 634)",
            "arrow-flight/src/lib.rs - FlightEndpoint::new (line 761)",
            "arrow-flight/src/lib.rs - FlightInfo::new (line 536)",
            "test_do_exchange_error_stream",
            "test_cancel_flight_info",
            "test_do_action_error_in_stream",
            "test_do_action_error",
            "test_do_action",
            "test_do_exchange_error",
            "test_get_schema_error",
            "test_get_flight_info",
            "test_handshake_error",
            "test_get_flight_info_error",
            "test_handshake",
            "test_get_schema",
            "test_list_actions_error",
            "test_list_flights",
            "test_list_actions_error_in_stream",
            "test_list_flights_error_in_stream",
            "test_list_flights_error",
            "test_poll_flight_info_error",
            "test_renew_flight_endpoint",
            "test_do_exchange",
            "test_do_get",
            "test_poll_flight_info",
            "test_do_get_error",
            "test_list_actions",
            "test_do_put_error_stream_server",
            "test_do_get_error_in_record_batch_stream",
            "test_do_put_error_client",
            "test_do_put_error_server",
            "test_do_put",
            "test_do_put_error_client_and_server",
            "test_empty",
            "test_app_metadata",
            "test_dictionary_one",
            "test_max_message_size",
            "test_with_flight_descriptor",
            "test_empty_batch",
            "test_primitive_one",
            "test_chained_streams_data_decoder",
            "test_mismatched_schema_message",
            "test_primitive_many",
            "test_dictionary_many",
            "test_zero_batches_schema_specified",
            "test_zero_batches_no_schema",
            "test_zero_batches_dictionary_schema_specified",
            "test_primitive_empty",
            "test_schema_metadata",
            "test_max_message_size_fuzz"
        ],
        "FAIL_TO_FAIL": [],
        "PASS_TO_FAIL": []
    }
]